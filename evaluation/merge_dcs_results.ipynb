{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6dd7549b-5e2f-4b15-a48c-6afcc7dd8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1501f9c-61b2-464b-9d0a-993cbc573aa4",
   "metadata": {},
   "source": [
    "## Merge data characteristics and regression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e28eb4f0-c603-4813-b7c3-c52f4631d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression = pd.read_excel(\"../stats/final_table.xlsx\")\n",
    "bx_age = pd.read_csv(\"../stats/stats_BX_age.csv\")\n",
    "ml1m_age = pd.read_csv(\"../stats/stats_ml1m_age.csv\")\n",
    "ml1m_gender = pd.read_csv(\"../stats/stats_ml1m_gender.csv\")\n",
    "\n",
    "bx_age[\"Sensitive Feature\"] = \"Age\"\n",
    "ml1m_age[\"Sensitive Feature\"] = \"Age\"\n",
    "ml1m_gender[\"Sensitive Feature\"] = \"Gender\"\n",
    "\n",
    "df_concat = pd.concat([bx_age, ml1m_age, ml1m_gender], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b3b84d36-ccd6-4a11-bd92-424e9340a2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Compute the correlation matrix\\ncorrelation_matrix = df_regression[[\\'ndcg@5\\', \\'recall@5\\', \\'mrr@5\\',\\n       \\'Differential Fairness of sensitive attribute\\', \\'giniindex@5\\',\\n       \\'popularitypercentage@5\\', \\'Value Unfairness of sensitive attribute\\',\\n       \\'Absolute Unfairness of sensitive attribute\\',\\n       \\'Underestimation Unfairness of sensitive attribute\\',\\n       \\'Overestimation Unfairness of sensitive attribute\\',\\n       \\'NonParity Unfairness of sensitive attribute\\', \\'Absolute Difference\\',\\n       \\'KS Statistic of sensitive attribute\\', \\'Generalized Cross Entropy\\',\\n       \\'hit@5\\']].corr()\\n\\n# Plot the heatmap\\nplt.figure(figsize=(8, 6))\\nsns.heatmap(correlation_matrix, annot=True, cmap=\\'coolwarm\\', fmt=\".2f\", linewidths=0.5)\\nplt.title(\"Feature Correlation Heatmap\")\\nplt.show()'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df_regression[['ndcg@5', 'recall@5', 'mrr@5',\n",
    "       'Differential Fairness of sensitive attribute', 'giniindex@5',\n",
    "       'popularitypercentage@5', 'Value Unfairness of sensitive attribute',\n",
    "       'Absolute Unfairness of sensitive attribute',\n",
    "       'Underestimation Unfairness of sensitive attribute',\n",
    "       'Overestimation Unfairness of sensitive attribute',\n",
    "       'NonParity Unfairness of sensitive attribute', 'Absolute Difference',\n",
    "       'KS Statistic of sensitive attribute', 'Generalized Cross Entropy',\n",
    "       'hit@5']].corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a12405e4-9f7e-4117-90a2-880180938bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN for \"Value Unfairness\" using group mean\n",
    "df_regression[\"Value Unfairness of sensitive attribute\"] = df_regression.groupby([\"Model Name\", \"Sensitive Feature\"])[\n",
    "    \"Value Unfairness of sensitive attribute\"].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "# Fill NaN for \"Absolute Unfairness\" using group median\n",
    "df_regression[\"Absolute Unfairness of sensitive attribute\"] = df_regression.groupby([\"Model Name\", \"Sensitive Feature\"])[\n",
    "    \"Absolute Unfairness of sensitive attribute\"].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "# Fill NaN for \"Underestimation Unfairness\" using group mean\n",
    "df_regression[\"Underestimation Unfairness of sensitive attribute\"] = df_regression.groupby([\"Model Name\", \"Sensitive Feature\"])[\n",
    "    \"Underestimation Unfairness of sensitive attribute\"].transform(\n",
    "    lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c35d1217-23ae-43a0-aada-d14d0600af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regression.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df_final = df_regression.merge(\n",
    "    df_concat, \n",
    "    how=\"left\", \n",
    "    on=['Dataset', 'Subset ID', 'Is Filtered', 'Sensitive Feature']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "edeaae51-53b9-4fd3-bd19-71b596dfbdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to replace NaN values in all numeric columns with group-specific mean + optional noise\n",
    "def replace_nan_with_group_mean_all(df, groupby_cols, add_noise=False):\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns  # Select numeric columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        # Compute group-specific mean and std for the current column\n",
    "        group_stats = df.groupby(groupby_cols)[col].agg(['mean', 'std'])\n",
    "        \n",
    "        # Function to replace NaN values\n",
    "        def replace_nan(row, col, group_stats, add_noise):\n",
    "            if pd.isna(row[col]):\n",
    "                mean_value = group_stats.loc[(row[groupby_cols[0]], row[groupby_cols[1]], row[groupby_cols[2]]), 'mean']\n",
    "                if add_noise:\n",
    "                    std_value = group_stats.loc[(row[groupby_cols[0]], row[groupby_cols[1]], row[groupby_cols[2]]), 'std']\n",
    "                    noise = random.uniform(-0.5 * std_value, 0.5 * std_value) if pd.notna(std_value) else 0\n",
    "                    return mean_value + noise\n",
    "                return mean_value\n",
    "            return row[col]\n",
    "        \n",
    "        # Apply the replacement function to the column\n",
    "        df[col] = df.apply(replace_nan, axis=1, col=col, group_stats=group_stats, add_noise=add_noise)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "09c926a9-be40-42be-bafb-5ecf8ac5f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\"Model Name\", \"Dataset\", \"Sensitive Feature\"]\n",
    "df_final = replace_nan_with_group_mean_all(df_final, groupby_columns, add_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "24350407-3200-432c-9221-a7b4bda89bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 45)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "161458db-85e0-410e-94cf-374a469db4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(\"df_regression.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4cc53-a342-48e3-acab-122492f38931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
